{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 7. Classification\n",
    "\n",
    "* 추가할 부분\n",
    "\n",
    "> - GLMNet 구동 원리와 사이킷런과의 차이(python, R)\n",
    "> - 사이킷런에서의 Decision Tree 이용법 비교(Python, R)\n",
    "> - 사이킷런에서의 KNN 이용법 비교 및 R에서의 knn 이용법 비교\n",
    "> - LIBSVM 구동법 확인 및 사이킷런과 R의 e1071 사용법과의 차이 비교"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"C:\\\\Users\\\\user\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "findaccuracy (generic function with 1 method)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# findaccuracy 함수 설정\n",
    "findaccuracy(p, r) = sum(p .== r)/length(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: Package GLMnet not found in current path:\n- Run `import Pkg; Pkg.add(\"GLMnet\")` to install the GLMnet package.\n",
     "output_type": "error",
     "traceback": [
      "ArgumentError: Package GLMnet not found in current path:\n- Run `import Pkg; Pkg.add(\"GLMnet\")` to install the GLMnet package.\n",
      "",
      "Stacktrace:",
      " [1] require(into::Module, mod::Symbol)",
      "   @ Base .\\loading.jl:871",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "using GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m GLMNet ─ v0.6.1\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [8d5ece8b] \u001b[39m\u001b[92m+ GLMNet v0.6.1\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      " \u001b[90m [8d5ece8b] \u001b[39m\u001b[92m+ GLMNet v0.6.1\u001b[39m\n",
      " \u001b[90m [78c6b45d] \u001b[39m\u001b[92m+ glmnet_jll v5.0.0+0\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mglmnet_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mGLMNet\n",
      "2 dependencies successfully precompiled in 7 seconds (296 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "# Pkg.add(\"GLMNet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "using GLMNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "using RDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "using MLBase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m DecisionTree ─ v0.10.10\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [7806a523] \u001b[39m\u001b[92m+ DecisionTree v0.10.10\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      " \u001b[90m [7806a523] \u001b[39m\u001b[92m+ DecisionTree v0.10.10\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39mDecisionTree\n",
      "1 dependency successfully precompiled in 3 seconds (298 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "# Pkg.add(\"DecisionTree\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DecisionTree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [b8a86587] \u001b[39m\u001b[92m+ NearestNeighbors v0.4.8\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\user\\.julia\\environments\\v1.6\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# Pkg.add(\"NearestNeighbors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "using NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LinearAlgebra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataStructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [864edb3b] \u001b[39m\u001b[92m+ DataStructures v0.18.9\u001b[39m\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `C:\\Users\\user\\.julia\\environments\\v1.6\\Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "# Pkg.add(\"DataStructures\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "using DataStructures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m libsvm_jll ──── v3.24.0+1\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m liblinear_jll ─ v2.30.0+0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LIBSVM ──────── v0.6.0\n",
      "\u001b[32m\u001b[1m   Installed\u001b[22m\u001b[39m LIBLINEAR ───── v0.6.0\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Project.toml`\n",
      " \u001b[90m [b1bec4e5] \u001b[39m\u001b[92m+ LIBSVM v0.6.0\u001b[39m\n",
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m `C:\\Users\\user\\.julia\\environments\\v1.6\\Manifest.toml`\n",
      " \u001b[90m [2d691ee1] \u001b[39m\u001b[92m+ LIBLINEAR v0.6.0\u001b[39m\n",
      " \u001b[90m [b1bec4e5] \u001b[39m\u001b[92m+ LIBSVM v0.6.0\u001b[39m\n",
      " \u001b[90m [275f1f90] \u001b[39m\u001b[92m+ liblinear_jll v2.30.0+0\u001b[39m\n",
      " \u001b[90m [08558c22] \u001b[39m\u001b[92m+ libsvm_jll v3.24.0+1\u001b[39m\n",
      "\u001b[32m\u001b[1mPrecompiling\u001b[22m\u001b[39m project...\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mlibsvm_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mliblinear_jll\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39m\u001b[90mLIBLINEAR\u001b[39m\n",
      "\u001b[32m  ✓ \u001b[39mLIBSVM\n",
      "4 dependencies successfully precompiled in 4 seconds (299 already precompiled)\n"
     ]
    }
   ],
   "source": [
    "# Pkg.add(\"LIBSVM\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "using LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Pkg\n",
    "using GLMNet\n",
    "using RDatasets\n",
    "using MLBase\n",
    "using Plots\n",
    "using DecisionTree\n",
    "using Distances\n",
    "using NearestNeighbors\n",
    "using Random\n",
    "using LinearAlgebra\n",
    "using DataStructures\n",
    "using LIBSVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>SepalLength</th><th>SepalWidth</th><th>PetalLength</th><th>PetalWidth</th><th>Species</th></tr><tr><th></th><th>Float64</th><th>Float64</th><th>Float64</th><th>Float64</th><th>Cat…</th></tr></thead><tbody><p>150 rows × 5 columns</p><tr><th>1</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.2</td><td>setosa</td></tr><tr><th>2</th><td>4.9</td><td>3.0</td><td>1.4</td><td>0.2</td><td>setosa</td></tr><tr><th>3</th><td>4.7</td><td>3.2</td><td>1.3</td><td>0.2</td><td>setosa</td></tr><tr><th>4</th><td>4.6</td><td>3.1</td><td>1.5</td><td>0.2</td><td>setosa</td></tr><tr><th>5</th><td>5.0</td><td>3.6</td><td>1.4</td><td>0.2</td><td>setosa</td></tr><tr><th>6</th><td>5.4</td><td>3.9</td><td>1.7</td><td>0.4</td><td>setosa</td></tr><tr><th>7</th><td>4.6</td><td>3.4</td><td>1.4</td><td>0.3</td><td>setosa</td></tr><tr><th>8</th><td>5.0</td><td>3.4</td><td>1.5</td><td>0.2</td><td>setosa</td></tr><tr><th>9</th><td>4.4</td><td>2.9</td><td>1.4</td><td>0.2</td><td>setosa</td></tr><tr><th>10</th><td>4.9</td><td>3.1</td><td>1.5</td><td>0.1</td><td>setosa</td></tr><tr><th>11</th><td>5.4</td><td>3.7</td><td>1.5</td><td>0.2</td><td>setosa</td></tr><tr><th>12</th><td>4.8</td><td>3.4</td><td>1.6</td><td>0.2</td><td>setosa</td></tr><tr><th>13</th><td>4.8</td><td>3.0</td><td>1.4</td><td>0.1</td><td>setosa</td></tr><tr><th>14</th><td>4.3</td><td>3.0</td><td>1.1</td><td>0.1</td><td>setosa</td></tr><tr><th>15</th><td>5.8</td><td>4.0</td><td>1.2</td><td>0.2</td><td>setosa</td></tr><tr><th>16</th><td>5.7</td><td>4.4</td><td>1.5</td><td>0.4</td><td>setosa</td></tr><tr><th>17</th><td>5.4</td><td>3.9</td><td>1.3</td><td>0.4</td><td>setosa</td></tr><tr><th>18</th><td>5.1</td><td>3.5</td><td>1.4</td><td>0.3</td><td>setosa</td></tr><tr><th>19</th><td>5.7</td><td>3.8</td><td>1.7</td><td>0.3</td><td>setosa</td></tr><tr><th>20</th><td>5.1</td><td>3.8</td><td>1.5</td><td>0.3</td><td>setosa</td></tr><tr><th>21</th><td>5.4</td><td>3.4</td><td>1.7</td><td>0.2</td><td>setosa</td></tr><tr><th>22</th><td>5.1</td><td>3.7</td><td>1.5</td><td>0.4</td><td>setosa</td></tr><tr><th>23</th><td>4.6</td><td>3.6</td><td>1.0</td><td>0.2</td><td>setosa</td></tr><tr><th>24</th><td>5.1</td><td>3.3</td><td>1.7</td><td>0.5</td><td>setosa</td></tr><tr><th>25</th><td>4.8</td><td>3.4</td><td>1.9</td><td>0.2</td><td>setosa</td></tr><tr><th>26</th><td>5.0</td><td>3.0</td><td>1.6</td><td>0.2</td><td>setosa</td></tr><tr><th>27</th><td>5.0</td><td>3.4</td><td>1.6</td><td>0.4</td><td>setosa</td></tr><tr><th>28</th><td>5.2</td><td>3.5</td><td>1.5</td><td>0.2</td><td>setosa</td></tr><tr><th>29</th><td>5.2</td><td>3.4</td><td>1.4</td><td>0.2</td><td>setosa</td></tr><tr><th>30</th><td>4.7</td><td>3.2</td><td>1.6</td><td>0.2</td><td>setosa</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& SepalLength & SepalWidth & PetalLength & PetalWidth & Species\\\\\n",
       "\t\\hline\n",
       "\t& Float64 & Float64 & Float64 & Float64 & Cat…\\\\\n",
       "\t\\hline\n",
       "\t1 & 5.1 & 3.5 & 1.4 & 0.2 & setosa \\\\\n",
       "\t2 & 4.9 & 3.0 & 1.4 & 0.2 & setosa \\\\\n",
       "\t3 & 4.7 & 3.2 & 1.3 & 0.2 & setosa \\\\\n",
       "\t4 & 4.6 & 3.1 & 1.5 & 0.2 & setosa \\\\\n",
       "\t5 & 5.0 & 3.6 & 1.4 & 0.2 & setosa \\\\\n",
       "\t6 & 5.4 & 3.9 & 1.7 & 0.4 & setosa \\\\\n",
       "\t7 & 4.6 & 3.4 & 1.4 & 0.3 & setosa \\\\\n",
       "\t8 & 5.0 & 3.4 & 1.5 & 0.2 & setosa \\\\\n",
       "\t9 & 4.4 & 2.9 & 1.4 & 0.2 & setosa \\\\\n",
       "\t10 & 4.9 & 3.1 & 1.5 & 0.1 & setosa \\\\\n",
       "\t11 & 5.4 & 3.7 & 1.5 & 0.2 & setosa \\\\\n",
       "\t12 & 4.8 & 3.4 & 1.6 & 0.2 & setosa \\\\\n",
       "\t13 & 4.8 & 3.0 & 1.4 & 0.1 & setosa \\\\\n",
       "\t14 & 4.3 & 3.0 & 1.1 & 0.1 & setosa \\\\\n",
       "\t15 & 5.8 & 4.0 & 1.2 & 0.2 & setosa \\\\\n",
       "\t16 & 5.7 & 4.4 & 1.5 & 0.4 & setosa \\\\\n",
       "\t17 & 5.4 & 3.9 & 1.3 & 0.4 & setosa \\\\\n",
       "\t18 & 5.1 & 3.5 & 1.4 & 0.3 & setosa \\\\\n",
       "\t19 & 5.7 & 3.8 & 1.7 & 0.3 & setosa \\\\\n",
       "\t20 & 5.1 & 3.8 & 1.5 & 0.3 & setosa \\\\\n",
       "\t21 & 5.4 & 3.4 & 1.7 & 0.2 & setosa \\\\\n",
       "\t22 & 5.1 & 3.7 & 1.5 & 0.4 & setosa \\\\\n",
       "\t23 & 4.6 & 3.6 & 1.0 & 0.2 & setosa \\\\\n",
       "\t24 & 5.1 & 3.3 & 1.7 & 0.5 & setosa \\\\\n",
       "\t25 & 4.8 & 3.4 & 1.9 & 0.2 & setosa \\\\\n",
       "\t26 & 5.0 & 3.0 & 1.6 & 0.2 & setosa \\\\\n",
       "\t27 & 5.0 & 3.4 & 1.6 & 0.4 & setosa \\\\\n",
       "\t28 & 5.2 & 3.5 & 1.5 & 0.2 & setosa \\\\\n",
       "\t29 & 5.2 & 3.4 & 1.4 & 0.2 & setosa \\\\\n",
       "\t30 & 4.7 & 3.2 & 1.6 & 0.2 & setosa \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m150×5 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m SepalLength \u001b[0m\u001b[1m SepalWidth \u001b[0m\u001b[1m PetalLength \u001b[0m\u001b[1m PetalWidth \u001b[0m\u001b[1m Species   \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Float64     \u001b[0m\u001b[90m Float64    \u001b[0m\u001b[90m Cat…      \u001b[0m\n",
       "─────┼─────────────────────────────────────────────────────────────\n",
       "   1 │         5.1         3.5          1.4         0.2  setosa\n",
       "   2 │         4.9         3.0          1.4         0.2  setosa\n",
       "   3 │         4.7         3.2          1.3         0.2  setosa\n",
       "   4 │         4.6         3.1          1.5         0.2  setosa\n",
       "   5 │         5.0         3.6          1.4         0.2  setosa\n",
       "   6 │         5.4         3.9          1.7         0.4  setosa\n",
       "   7 │         4.6         3.4          1.4         0.3  setosa\n",
       "   8 │         5.0         3.4          1.5         0.2  setosa\n",
       "   9 │         4.4         2.9          1.4         0.2  setosa\n",
       "  10 │         4.9         3.1          1.5         0.1  setosa\n",
       "  11 │         5.4         3.7          1.5         0.2  setosa\n",
       "  ⋮  │      ⋮           ⋮            ⋮           ⋮           ⋮\n",
       " 141 │         6.7         3.1          5.6         2.4  virginica\n",
       " 142 │         6.9         3.1          5.1         2.3  virginica\n",
       " 143 │         5.8         2.7          5.1         1.9  virginica\n",
       " 144 │         6.8         3.2          5.9         2.3  virginica\n",
       " 145 │         6.7         3.3          5.7         2.5  virginica\n",
       " 146 │         6.7         3.0          5.2         2.3  virginica\n",
       " 147 │         6.3         2.5          5.0         1.9  virginica\n",
       " 148 │         6.5         3.0          5.2         2.0  virginica\n",
       " 149 │         6.2         3.4          5.4         2.3  virginica\n",
       " 150 │         5.9         3.0          5.1         1.8  virginica\n",
       "\u001b[36m                                                   129 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = dataset(\"datasets\", \"iris\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150×4 Matrix{Float64}:\n",
       " 5.1  3.5  1.4  0.2\n",
       " 4.9  3.0  1.4  0.2\n",
       " 4.7  3.2  1.3  0.2\n",
       " 4.6  3.1  1.5  0.2\n",
       " 5.0  3.6  1.4  0.2\n",
       " 5.4  3.9  1.7  0.4\n",
       " 4.6  3.4  1.4  0.3\n",
       " 5.0  3.4  1.5  0.2\n",
       " 4.4  2.9  1.4  0.2\n",
       " 4.9  3.1  1.5  0.1\n",
       " 5.4  3.7  1.5  0.2\n",
       " 4.8  3.4  1.6  0.2\n",
       " 4.8  3.0  1.4  0.1\n",
       " ⋮              \n",
       " 6.0  3.0  4.8  1.8\n",
       " 6.9  3.1  5.4  2.1\n",
       " 6.7  3.1  5.6  2.4\n",
       " 6.9  3.1  5.1  2.3\n",
       " 5.8  2.7  5.1  1.9\n",
       " 6.8  3.2  5.9  2.3\n",
       " 6.7  3.3  5.7  2.5\n",
       " 6.7  3.0  5.2  2.3\n",
       " 6.3  2.5  5.0  1.9\n",
       " 6.5  3.0  5.2  2.0\n",
       " 6.2  3.4  5.4  2.3\n",
       " 5.9  3.0  5.1  1.8"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = Matrix(iris[:, 1:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element CategoricalArrays.CategoricalArray{String,1,UInt8}:\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " \"setosa\"\n",
       " ⋮\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\"\n",
       " \"virginica\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irislabels = iris[:, 5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dict{CategoricalArrays.CategoricalValue{String, UInt8}, Int64} with 3 entries:\n",
       "  \"virginica\"  => 50\n",
       "  \"setosa\"     => 50\n",
       "  \"versicolor\" => 50"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "countmap(irislabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mc\u001b[22m\u001b[0m\u001b[1mo\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1mt\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mp\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "countmap(x; alg = :auto)\n",
       "countmap(x::AbstractVector, w::AbstractVector{<:Real}; alg = :auto)\n",
       "\\end{verbatim}\n",
       "Return a dictionary mapping each unique value in \\texttt{x} to its number of occurrences. A vector of weights \\texttt{w} can be provided when \\texttt{x} is a vector.\n",
       "\n",
       "\\begin{itemize}\n",
       "\\item \\texttt{:auto} (default): if \\texttt{StatsBase.radixsort\\_safe(eltype(x)) == true} then use                    \\texttt{:radixsort}, otherwise use \\texttt{:dict}.\n",
       "\n",
       "\n",
       "\\item \\texttt{:radixsort}:      if \\texttt{radixsort\\_safe(eltype(x)) == true} then use the                    \\href{https://en.wikipedia.org/wiki/Radix_sort}{radix sort}                    algorithm to sort the input vector which will generally lead to                    shorter running time. However the radix sort algorithm creates a                    copy of the input vector and hence uses more RAM. Choose \\texttt{:dict}                    if the amount of available RAM is a limitation.\n",
       "\n",
       "\n",
       "\\item \\texttt{:dict}:           use \\texttt{Dict}-based method which is generally slower but uses less                    RAM and is safe for any data type.\n",
       "\n",
       "\\end{itemize}\n"
      ],
      "text/markdown": [
       "```\n",
       "countmap(x; alg = :auto)\n",
       "countmap(x::AbstractVector, w::AbstractVector{<:Real}; alg = :auto)\n",
       "```\n",
       "\n",
       "Return a dictionary mapping each unique value in `x` to its number of occurrences. A vector of weights `w` can be provided when `x` is a vector.\n",
       "\n",
       "  * `:auto` (default): if `StatsBase.radixsort_safe(eltype(x)) == true` then use                    `:radixsort`, otherwise use `:dict`.\n",
       "  * `:radixsort`:      if `radixsort_safe(eltype(x)) == true` then use the                    [radix sort](https://en.wikipedia.org/wiki/Radix_sort)                    algorithm to sort the input vector which will generally lead to                    shorter running time. However the radix sort algorithm creates a                    copy of the input vector and hence uses more RAM. Choose `:dict`                    if the amount of available RAM is a limitation.\n",
       "  * `:dict`:           use `Dict`-based method which is generally slower but uses less                    RAM and is safe for any data type.\n"
      ],
      "text/plain": [
       "\u001b[36m  countmap(x; alg = :auto)\u001b[39m\n",
       "\u001b[36m  countmap(x::AbstractVector, w::AbstractVector{<:Real}; alg = :auto)\u001b[39m\n",
       "\n",
       "  Return a dictionary mapping each unique value in \u001b[36mx\u001b[39m to its number of\n",
       "  occurrences. A vector of weights \u001b[36mw\u001b[39m can be provided when \u001b[36mx\u001b[39m is a vector.\n",
       "\n",
       "    •  \u001b[36m:auto\u001b[39m (default): if \u001b[36mStatsBase.radixsort_safe(eltype(x)) == true\u001b[39m then\n",
       "       use \u001b[36m:radixsort\u001b[39m, otherwise use \u001b[36m:dict\u001b[39m.\n",
       "\n",
       "    •  \u001b[36m:radixsort\u001b[39m: if \u001b[36mradixsort_safe(eltype(x)) == true\u001b[39m then use the radix\n",
       "       sort (https://en.wikipedia.org/wiki/Radix_sort) algorithm to sort the\n",
       "       input vector which will generally lead to shorter running time.\n",
       "       However the radix sort algorithm creates a copy of the input vector\n",
       "       and hence uses more RAM. Choose \u001b[36m:dict\u001b[39m if the amount of available RAM\n",
       "       is a limitation.\n",
       "\n",
       "    •  \u001b[36m:dict\u001b[39m: use \u001b[36mDict\u001b[39m-based method which is generally slower but uses less\n",
       "       RAM and is safe for any data type."
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?countmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelMap (with 3 labels):\n",
       "[1] setosa\n",
       "[2] versicolor\n",
       "[3] virginica\n"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "irislabelsmap = labelmap(irislabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "150-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = labelencode(irislabelsmap, irislabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "perclass_splits (generic function with 1 method)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function perclass_splits(y, at)\n",
    "    uids = unique(y)\n",
    "    keepids = []\n",
    "    for ui in uids\n",
    "        curids = findall(y .== ui)\n",
    "        rowids = randsubseq(curids, at)\n",
    "        push!(keepids, rowids...)\n",
    "    end\n",
    "    return keepids\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mq\u001b[22m \u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\u001b[0m\u001b[1ms\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mq\u001b[22m! \u001b[0m\u001b[1mR\u001b[22m\u001b[0m\u001b[1ma\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mom\u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mb\u001b[22m St\u001b[0m\u001b[1mr\u001b[22m\u001b[0m\u001b[1ma\u001b[22mtifiedRa\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1md\u001b[22mom\u001b[0m\u001b[1mS\u001b[22m\u001b[0m\u001b[1mu\u001b[22m\u001b[0m\u001b[1mb\u001b[22m\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "\\begin{verbatim}\n",
       "randsubseq([rng=GLOBAL_RNG,] A, p) -> Vector\n",
       "\\end{verbatim}\n",
       "Return a vector consisting of a random subsequence of the given array \\texttt{A}, where each element of \\texttt{A} is included (in order) with independent probability \\texttt{p}. (Complexity is linear in \\texttt{p*length(A)}, so this function is efficient even if \\texttt{p} is small and \\texttt{A} is large.) Technically, this process is known as \"Bernoulli sampling\" of \\texttt{A}.\n",
       "\n",
       "\\section{Examples}\n",
       "\\begin{verbatim}\n",
       "julia> rng = MersenneTwister(1234);\n",
       "\n",
       "julia> randsubseq(rng, 1:8, 0.3)\n",
       "2-element Vector{Int64}:\n",
       " 7\n",
       " 8\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "```\n",
       "randsubseq([rng=GLOBAL_RNG,] A, p) -> Vector\n",
       "```\n",
       "\n",
       "Return a vector consisting of a random subsequence of the given array `A`, where each element of `A` is included (in order) with independent probability `p`. (Complexity is linear in `p*length(A)`, so this function is efficient even if `p` is small and `A` is large.) Technically, this process is known as \"Bernoulli sampling\" of `A`.\n",
       "\n",
       "# Examples\n",
       "\n",
       "```jldoctest\n",
       "julia> rng = MersenneTwister(1234);\n",
       "\n",
       "julia> randsubseq(rng, 1:8, 0.3)\n",
       "2-element Vector{Int64}:\n",
       " 7\n",
       " 8\n",
       "```\n"
      ],
      "text/plain": [
       "\u001b[36m  randsubseq([rng=GLOBAL_RNG,] A, p) -> Vector\u001b[39m\n",
       "\n",
       "  Return a vector consisting of a random subsequence of the given array \u001b[36mA\u001b[39m,\n",
       "  where each element of \u001b[36mA\u001b[39m is included (in order) with independent probability\n",
       "  \u001b[36mp\u001b[39m. (Complexity is linear in \u001b[36mp*length(A)\u001b[39m, so this function is efficient even\n",
       "  if \u001b[36mp\u001b[39m is small and \u001b[36mA\u001b[39m is large.) Technically, this process is known as\n",
       "  \"Bernoulli sampling\" of \u001b[36mA\u001b[39m.\n",
       "\n",
       "\u001b[1m  Examples\u001b[22m\n",
       "\u001b[1m  ≡≡≡≡≡≡≡≡≡≡\u001b[22m\n",
       "\n",
       "\u001b[36m  julia> rng = MersenneTwister(1234);\u001b[39m\n",
       "\u001b[36m  \u001b[39m\n",
       "\u001b[36m  julia> randsubseq(rng, 1:8, 0.3)\u001b[39m\n",
       "\u001b[36m  2-element Vector{Int64}:\u001b[39m\n",
       "\u001b[36m   7\u001b[39m\n",
       "\u001b[36m   8\u001b[39m"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?randsubseq # R의 sample 함수랑 비슷!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MersenneTwister(123)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "using Random\n",
    "Random.seed!(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Vector{Int64}:\n",
       "   1\n",
       "   2\n",
       "  13\n",
       "  21\n",
       "  24\n",
       "  26\n",
       "  28\n",
       "  30\n",
       "  32\n",
       "  34\n",
       "  37\n",
       "  38\n",
       "  44\n",
       "   ⋮\n",
       " 107\n",
       " 108\n",
       " 109\n",
       " 115\n",
       " 128\n",
       " 133\n",
       " 134\n",
       " 137\n",
       " 141\n",
       " 144\n",
       " 146\n",
       " 148"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainids = perclass_splits(y, 0.7)\n",
    "testids = setdiff(1:length(y), trainids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 예측값이 연속적인 값을 경우 사용하기 위한 클래스 지정 함수 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "assign_class (generic function with 1 method)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assign_class(predictedvalue) = argmin(abs.(predictedvalue .- [1, 2, 3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Lasso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Lasso, Ridge, ElasticNet은 GLMNet.jl 패키지 사용\n",
    "\n",
    "> (참고) GLMNet.jl 패키지는 R의 glmnet 패키지와 동일하다고 볼 수 있음 \n",
    "> glmnet is an R package by Jerome Friedman, Trevor Hastie, Rob Tibshirani that fits entire Lasso or ElasticNet regularization paths for linear, logistic, multinomial, and Cox models using cyclic coordinate descent. This Julia package wraps the Fortran code from glmnet.\n",
    "\n",
    "> - https://github.com/JuliaStats/GLMNet.jl\n",
    "\n",
    ">* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html\n",
    ">* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html\n",
    ">* https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.ElasticNet.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "search: \u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mt\u001b[22m \u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mt\u001b[22m! \u001b[0m\u001b[1mg\u001b[22m\u001b[0m\u001b[1ml\u001b[22m\u001b[0m\u001b[1mm\u001b[22m\u001b[0m\u001b[1mn\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mt\u001b[22mcv \u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mM\u001b[22m\u001b[0m\u001b[1mN\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mt\u001b[22m \u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mM\u001b[22m\u001b[0m\u001b[1mN\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mt\u001b[22mPath \u001b[0m\u001b[1mG\u001b[22m\u001b[0m\u001b[1mL\u001b[22m\u001b[0m\u001b[1mM\u001b[22m\u001b[0m\u001b[1mN\u001b[22m\u001b[0m\u001b[1me\u001b[22m\u001b[0m\u001b[1mt\u001b[22mCrossValidation\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/latex": [
       "No documentation found.\n",
       "\n",
       "\\texttt{GLMNet.glmnet} is a \\texttt{Function}.\n",
       "\n",
       "\\begin{verbatim}\n",
       "# 16 methods for generic function \"glmnet\":\n",
       "[1] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractVector{var\"#s89\"} where var\"#s89\"<:Number) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:494\n",
       "[2] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractVector{var\"#s88\"} where var\"#s88\"<:Number, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:494\n",
       "[3] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractMatrix{T} where T, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:498\n",
       "[4] glmnet(X::Matrix{Float64}, y::Vector{Float64}) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:490\n",
       "[5] glmnet(X::AbstractMatrix{T} where T, time::AbstractVector{T} where T, status::AbstractVector{T} where T) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:151\n",
       "[6] glmnet(X::AbstractMatrix{T} where T, time::AbstractVector{T} where T, status::AbstractVector{T} where T, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:151\n",
       "[7] glmnet(X::Matrix{Float64}, y::Vector{Float64}, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:490\n",
       "[8] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:496\n",
       "[9] glmnet(X::Matrix{T} where T, y::Matrix{T} where T, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:500\n",
       "[10] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::Distributions.Multinomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:185\n",
       "[11] glmnet(X::AbstractMatrix{T} where T, y::AbstractMatrix{T} where T, family::Distributions.Multinomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:188\n",
       "[12] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:145\n",
       "[13] glmnet(X::AbstractMatrix{T} where T, y::AbstractVector{var\"#s89\"} where var\"#s89\"<:Number) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:492\n",
       "[14] glmnet(X::AbstractMatrix{T} where T, y::AbstractVector{var\"#s88\"} where var\"#s88\"<:Number, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:492\n",
       "[15] glmnet(X::AbstractMatrix{T} where T, y::AbstractMatrix{T} where T, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:148\n",
       "[16] glmnet(X::AbstractMatrix{T} where T, y; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:191\n",
       "\\end{verbatim}\n"
      ],
      "text/markdown": [
       "No documentation found.\n",
       "\n",
       "`GLMNet.glmnet` is a `Function`.\n",
       "\n",
       "```\n",
       "# 16 methods for generic function \"glmnet\":\n",
       "[1] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractVector{var\"#s89\"} where var\"#s89\"<:Number) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:494\n",
       "[2] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractVector{var\"#s88\"} where var\"#s88\"<:Number, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:494\n",
       "[3] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractMatrix{T} where T, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:498\n",
       "[4] glmnet(X::Matrix{Float64}, y::Vector{Float64}) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:490\n",
       "[5] glmnet(X::AbstractMatrix{T} where T, time::AbstractVector{T} where T, status::AbstractVector{T} where T) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:151\n",
       "[6] glmnet(X::AbstractMatrix{T} where T, time::AbstractVector{T} where T, status::AbstractVector{T} where T, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:151\n",
       "[7] glmnet(X::Matrix{Float64}, y::Vector{Float64}, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:490\n",
       "[8] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:496\n",
       "[9] glmnet(X::Matrix{T} where T, y::Matrix{T} where T, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:500\n",
       "[10] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::Distributions.Multinomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:185\n",
       "[11] glmnet(X::AbstractMatrix{T} where T, y::AbstractMatrix{T} where T, family::Distributions.Multinomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:188\n",
       "[12] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:145\n",
       "[13] glmnet(X::AbstractMatrix{T} where T, y::AbstractVector{var\"#s89\"} where var\"#s89\"<:Number) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:492\n",
       "[14] glmnet(X::AbstractMatrix{T} where T, y::AbstractVector{var\"#s88\"} where var\"#s88\"<:Number, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:492\n",
       "[15] glmnet(X::AbstractMatrix{T} where T, y::AbstractMatrix{T} where T, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:148\n",
       "[16] glmnet(X::AbstractMatrix{T} where T, y; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:191\n",
       "```\n"
      ],
      "text/plain": [
       "  No documentation found.\n",
       "\n",
       "  \u001b[36mGLMNet.glmnet\u001b[39m is a \u001b[36mFunction\u001b[39m.\n",
       "\n",
       "\u001b[36m  # 16 methods for generic function \"glmnet\":\u001b[39m\n",
       "\u001b[36m  [1] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractVector{var\"#s89\"} where var\"#s89\"<:Number) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:494\u001b[39m\n",
       "\u001b[36m  [2] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractVector{var\"#s88\"} where var\"#s88\"<:Number, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:494\u001b[39m\n",
       "\u001b[36m  [3] glmnet(X::SparseArrays.SparseMatrixCSC, y::AbstractMatrix{T} where T, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:498\u001b[39m\n",
       "\u001b[36m  [4] glmnet(X::Matrix{Float64}, y::Vector{Float64}) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:490\u001b[39m\n",
       "\u001b[36m  [5] glmnet(X::AbstractMatrix{T} where T, time::AbstractVector{T} where T, status::AbstractVector{T} where T) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:151\u001b[39m\n",
       "\u001b[36m  [6] glmnet(X::AbstractMatrix{T} where T, time::AbstractVector{T} where T, status::AbstractVector{T} where T, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:151\u001b[39m\n",
       "\u001b[36m  [7] glmnet(X::Matrix{Float64}, y::Vector{Float64}, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:490\u001b[39m\n",
       "\u001b[36m  [8] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:496\u001b[39m\n",
       "\u001b[36m  [9] glmnet(X::Matrix{T} where T, y::Matrix{T} where T, family::Distributions.Binomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:500\u001b[39m\n",
       "\u001b[36m  [10] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::Distributions.Multinomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:185\u001b[39m\n",
       "\u001b[36m  [11] glmnet(X::AbstractMatrix{T} where T, y::AbstractMatrix{T} where T, family::Distributions.Multinomial; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:188\u001b[39m\n",
       "\u001b[36m  [12] glmnet(X::Matrix{Float64}, y::Matrix{Float64}, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:145\u001b[39m\n",
       "\u001b[36m  [13] glmnet(X::AbstractMatrix{T} where T, y::AbstractVector{var\"#s89\"} where var\"#s89\"<:Number) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:492\u001b[39m\n",
       "\u001b[36m  [14] glmnet(X::AbstractMatrix{T} where T, y::AbstractVector{var\"#s88\"} where var\"#s88\"<:Number, family::Distributions.Distribution; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\GLMNet.jl:492\u001b[39m\n",
       "\u001b[36m  [15] glmnet(X::AbstractMatrix{T} where T, y::AbstractMatrix{T} where T, family::CoxPH; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\CoxNet.jl:148\u001b[39m\n",
       "\u001b[36m  [16] glmnet(X::AbstractMatrix{T} where T, y; kw...) in GLMNet at C:\\Users\\user\\.julia\\packages\\GLMNet\\uXUb5\\src\\Multinomial.jl:191\u001b[39m"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?glmnet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting models\n",
    "\n",
    "glmnet has two required parameters: the m x n predictor matrix X and the dependent variable y. It additionally accepts an optional third argument, family, which can be used to specify a generalized linear model. Currently, only Normal() (least squares, default), Binomial() (logistic), and Poisson() are supported, although the glmnet Fortran code also implements a Cox model. For logistic models, y is a m x 2 matrix, where the first column is the count of negative responses for each row in X and the second column is the count of positive responses. For all other models, y is a vector.\n",
    "\n",
    "- [glmnet] also accepts many optional parameters, described below:\n",
    "\n",
    "- weights: A vector of weights for each sample of the same size as y.\n",
    "\n",
    "- alpha: The tradeoff between lasso and ridge regression. This defaults to 1.0, which specifies a lasso model.\n",
    "\n",
    "penalty_factor: A vector of length n of penalties for each predictor in X. This defaults to all ones, which weights each predictor \n",
    "equally. To specify that a predictor should be unpenalized, set the corresponding entry to zero.\n",
    "\n",
    "constraints: An n x 2 matrix specifying lower bounds (first column) and upper bounds (second column) on each predictor. By default, this is [-Inf Inf] for each predictor in X.\n",
    "\n",
    "dfmax: The maximum number of predictors in the largest model.\n",
    "\n",
    "pmax: The maximum number of predictors in any model.\n",
    "\n",
    "nlambda: The number of values of λ along the path to consider.\n",
    "\n",
    "lambda_min_ratio: The smallest λ value to consider, as a ratio of the value of λ that gives the null model (i.e., the model with only an intercept). If the number of observations exceeds the number of variables, this defaults to 0.0001, otherwise 0.01.\n",
    "\n",
    "lambda: The λ values to consider. By default, this is determined from nlambda and lambda_min_ratio.\n",
    "\n",
    "tol: Convergence criterion. Defaults to 1e-7.\n",
    "\n",
    "standardize: Whether to standardize predictors so that they are in the same units. Defaults to true. Beta values are always presented on the original scale.\n",
    "\n",
    "intercept: Whether to fit an intercept term. The intercept is always unpenalized. Defaults to true.\n",
    "\n",
    "maxit: The maximum number of iterations of the cyclic coordinate descent algorithm. If convergence is not achieved, a warning is returned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Solution Path (73 solutions for 4 predictors in 1135 passes):\n",
       "───────────────────────────────\n",
       "      df   pct_dev            λ\n",
       "───────────────────────────────\n",
       " [1]   0  0.0       0.808902\n",
       " [2]   1  0.15649   0.737042\n",
       " [3]   1  0.286411  0.671565\n",
       " [4]   1  0.394274  0.611905\n",
       " [5]   2  0.484985  0.557545\n",
       " [6]   2  0.560524  0.508014\n",
       " [7]   2  0.623229  0.462884\n",
       " [8]   2  0.675286  0.421762\n",
       " [9]   2  0.718504  0.384294\n",
       "[10]   2  0.754383  0.350154\n",
       "[11]   2  0.784176  0.319048\n",
       "[12]   2  0.808906  0.290704\n",
       "[13]   2  0.829435  0.264879\n",
       "[14]   2  0.846478  0.241348\n",
       "[15]   2  0.860627  0.219907\n",
       "[16]   2  0.872374  0.200371\n",
       "[17]   2  0.882125  0.182571\n",
       "[18]   2  0.890221  0.166352\n",
       "[19]   2  0.896942  0.151574\n",
       "[20]   2  0.902521  0.138108\n",
       "[21]   2  0.907153  0.125839\n",
       "[22]   2  0.910998  0.11466\n",
       "[23]   2  0.91419   0.104474\n",
       "[24]   2  0.91684   0.0951926\n",
       "[25]   2  0.91904   0.0867359\n",
       "[26]   2  0.920865  0.0790306\n",
       "[27]   2  0.922381  0.0720097\n",
       "[28]   3  0.924062  0.0656126\n",
       "[29]   3  0.925582  0.0597837\n",
       "[30]   3  0.926844  0.0544727\n",
       "[31]   3  0.927891  0.0496335\n",
       "[32]   3  0.928761  0.0452242\n",
       "[33]   3  0.929484  0.0412066\n",
       "[34]   3  0.930083  0.0375459\n",
       "[35]   3  0.930581  0.0342104\n",
       "[36]   3  0.930994  0.0311713\n",
       "[37]   3  0.931337  0.0284021\n",
       "[38]   3  0.931623  0.0258789\n",
       "[39]   3  0.931859  0.0235799\n",
       "[40]   3  0.932056  0.0214852\n",
       "[41]   3  0.932219  0.0195765\n",
       "[42]   3  0.932354  0.0178374\n",
       "[43]   3  0.932466  0.0162527\n",
       "[44]   3  0.93256   0.0148089\n",
       "[45]   3  0.932637  0.0134933\n",
       "[46]   3  0.932702  0.0122946\n",
       "[47]   3  0.932756  0.0112024\n",
       "[48]   3  0.9328    0.0102072\n",
       "[49]   4  0.93284   0.00930041\n",
       "[50]   4  0.9332    0.00847419\n",
       "[51]   4  0.933638  0.00772136\n",
       "[52]   4  0.93402   0.00703542\n",
       "[53]   4  0.934341  0.00641041\n",
       "[54]   4  0.934609  0.00584093\n",
       "[55]   4  0.934829  0.00532204\n",
       "[56]   4  0.935014  0.00484924\n",
       "[57]   4  0.935169  0.00441845\n",
       "[58]   4  0.935298  0.00402593\n",
       "[59]   4  0.935406  0.00366827\n",
       "[60]   4  0.935493  0.00334239\n",
       "[61]   4  0.935569  0.00304547\n",
       "[62]   4  0.935629  0.00277491\n",
       "[63]   4  0.935682  0.0025284\n",
       "[64]   4  0.935726  0.00230378\n",
       "[65]   4  0.935762  0.00209912\n",
       "[66]   4  0.935792  0.00191264\n",
       "[67]   4  0.935818  0.00174273\n",
       "[68]   4  0.935839  0.00158791\n",
       "[69]   4  0.935856  0.00144684\n",
       "[70]   4  0.93587   0.00131831\n",
       "[71]   4  0.935883  0.00120119\n",
       "[72]   4  0.935893  0.00109448\n",
       "[73]   4  0.935902  0.000997252\n",
       "───────────────────────────────"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_1 = glmnet(X[trainids, :], y[trainids]) #alpha(sklearn에서의 L1 ration)의 default 값이 1 이므로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "73-element Vector{Float64}:\n",
       " 1.9900000000000015\n",
       " 1.8804564159276511\n",
       " 1.7806443819495192\n",
       " 1.6896993739765123\n",
       " 1.594378610353271\n",
       " 1.5049382090408558\n",
       " 1.4235266804776043\n",
       " 1.3493588117020523\n",
       " 1.2817820990128395\n",
       " 1.2202096196732066\n",
       " 1.163980294143869\n",
       " 1.1128389377503884\n",
       " 1.066257046651712\n",
       " ⋮\n",
       " 1.1790015574826218\n",
       " 1.187517310459731\n",
       " 1.1951937031552216\n",
       " 1.2021553369848859\n",
       " 1.208469976169066\n",
       " 1.214382692177558\n",
       " 1.2196578722491997\n",
       " 1.2244100262558657\n",
       " 1.228690967166628\n",
       " 1.2327576673244245\n",
       " 1.2363286553876363\n",
       " 1.2397249463668616"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_1.a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: both MLBase and GLMNet export \"coef\"; uses of it in module Main must be qualified\n"
     ]
    },
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: coef not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: coef not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[44]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "coef(path_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Cross Validation\n",
       "73 models for 4 predictors in 10 folds\n",
       "Best λ 0.001 (mean loss 0.051, std 0.007)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv = glmnetcv(X[trainids, :], y[trainids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "최적 람다값을 추출"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.012294594776065372"
     ]
    }
   ],
   "source": [
    "# choose the best lambda to predict with.\n",
    "path = glmnet(X[trainids, :], y[trainids])\n",
    "cv = glmnetcv(X[trainids, :], y[trainids])\n",
    "mylambda = path.lambda[argmin(cv.meanloss)]\n",
    "\n",
    "print(mylambda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Least Squares GLMNet Solution Path (1 solutions for 4 predictors in 83 passes):\n",
       "────────────────────────────\n",
       "     df   pct_dev          λ\n",
       "────────────────────────────\n",
       "[1]   3  0.932702  0.0122946\n",
       "────────────────────────────"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = glmnet(X[trainids, :], y[trainids], lambda = [mylambda])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.012294594776065372"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.lambda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$names\n",
    " [1] \"a0\"        \"beta\"      \"dfmat\"     \"df\"        \"dim\"       \"lambda\"    \"dev.ratio\" \"nulldev\"   \"npasses\"  \n",
    "[10] \"jerr\"      \"offset\"    \"call\"      \"nobs\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1-element Vector{Float64}:\n",
       " 0.9483636076467223"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.a0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 CompressedPredictorMatrix:\n",
       "  0.0\n",
       " -0.09543015992081726\n",
       "  0.1440166266049501\n",
       "  0.6748624842387528"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path.betas # coef(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GLMNetPath{Distributions.Normal{Float64}, Vector{Float64}, CompressedPredictorMatrix}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "UndefVarError: terms not defined",
     "output_type": "error",
     "traceback": [
      "UndefVarError: terms not defined",
      "",
      "Stacktrace:",
      " [1] top-level scope",
      "   @ In[53]:1",
      " [2] eval",
      "   @ .\\boot.jl:360 [inlined]",
      " [3] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "   @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "terms(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×1 Matrix{Float64}:\n",
       "  0.0\n",
       " -0.09543015992081726\n",
       "  0.1440166266049501\n",
       "  0.6748624842387528"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(Matrix, path.betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4×73 Matrix{Float64}:\n",
       " 0.0  0.0        0.0       0.0       …  -0.12822    -0.129945   -0.131617\n",
       " 0.0  0.0        0.0       0.0          -0.0324123  -0.0314856  -0.0305667\n",
       " 0.0  0.0        0.0       0.0           0.236176    0.237471    0.238729\n",
       " 0.0  0.0922861  0.176374  0.252991      0.61588     0.614923    0.613983"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert(Matrix, path_1.betas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×1 Matrix{Float64}:\n",
       " 0.9509538220185427\n",
       " 0.9986689019789514\n",
       " 0.9311826535550761\n",
       " 1.0037018259921093\n",
       " 1.215703587255817\n",
       " 1.0274722272999413\n",
       " 0.9653554846790378\n",
       " 1.0083861953157778\n",
       " 1.10987099751887\n",
       " 0.8841527100739706\n",
       " 0.9365521593580477\n",
       " 0.8739245576025857\n",
       " 1.2497021410350337\n",
       " ⋮\n",
       " 2.5051292507728347\n",
       " 2.793673363117293\n",
       " 2.759837113783145\n",
       " 3.035313917726686\n",
       " 2.5825070698782815\n",
       " 2.972349734181411\n",
       " 2.427937681911809\n",
       " 3.050064135076671\n",
       " 3.0786931830529163\n",
       " 3.0448689066184444\n",
       " 2.9631432999791425\n",
       " 2.7606845547075167"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = X[testids, :];\n",
    "predictions_lasso = GLMNet.predict(path, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×1 Matrix{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_class_lasso = assign_class.(predictions_lasso)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findaccuracy(pred_class_lasso, y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Ridge\n",
    "- We will use the same function but set alpha to zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the best lambda to predict with\n",
    "path = glmnet(X[trainids, :], y[trainids], alpha = 0); \n",
    "# ;를 붙이면 결과 출력 없이 진행 됨\n",
    "cv = glmnetcv(X[trainids, :], y[trainids], alpha = 0)\n",
    "mylambda = path.lambda[argmin(cv.meanloss)]\n",
    "path = glmnet(X[trainids, :], y[trainids], alpha = 0, lambda = [mylambda]);\n",
    "\n",
    "q = X[testids, :];\n",
    "predictions_ridge = GLMNet.predict(path, q)\n",
    "pred_class_ridge = assign_class.(predictions_ridge)\n",
    "findaccuracy(pred_class_ridge, y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Elastic Net\n",
    "- We will use the same function but set alpha to 0.5 (it's the combination of lasso and ridge)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# choose the best lambda to predict with.\n",
    "path = glmnet(X[trainids, :], y[trainids], alpha = 0.5);\n",
    "cv = glmnetcv(X[trainids, :], y[trainids], alpha = 0.5)\n",
    "mylambda = path.lambda[argmin(cv.meanloss)]\n",
    "path = glmnet(X[trainids, :], y[trainids], alpha = 0.5, lambda = [mylambda]);\n",
    "q = X[testids, :];\n",
    "predictions_EN = GLMNet.predict(path, q)\n",
    "pred_class_EN = assign_class.(predictions_EN)\n",
    "findaccuracy(pred_class_EN, y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Decision Tree\n",
    "- DecisionTree 패키지 사용\n",
    "\n",
    "> Julia implementation of Decision Tree (CART) and Random Forest algorithms\n",
    "\n",
    "> Available via:\n",
    "> * AutoMLPipeline.jl - create complex ML pipeline structures using simple expressions\n",
    "    - https://github.com/IBM/AutoMLPipeline.jl\n",
    "> * CombineML.jl - a heterogeneous ensemble learning package\n",
    "    - https://github.com/ppalmes/CombineML.jl\n",
    "> * MLJ.jl - a machine learning framework for Julia\n",
    "    - https://alan-turing-institute.github.io/MLJ.jl/dev/\n",
    "    - https://github.com/alan-turing-institute/MLJ.jl\n",
    "> * ScikitLearn.jl - Julia implementation of the scikit-learn API\n",
    "    - https://github.com/cstjean/ScikitLearn.jl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                2\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  nothing\n",
       "root:                     nothing"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = DecisionTreeClassifier(max_depth = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier\n",
       "max_depth:                2\n",
       "min_samples_leaf:         1\n",
       "min_samples_split:        2\n",
       "min_purity_increase:      0.0\n",
       "pruning_purity_threshold: 1.0\n",
       "n_subfeatures:            0\n",
       "classes:                  [1, 2, 3]\n",
       "root:                     Decision Tree\n",
       "Leaves: 3\n",
       "Depth:  2"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.fit!(model, X[trainids, :], y[trainids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = X[testids, :];\n",
    "predictions_DT = DecisionTree.predict(model, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.92"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findaccuracy(predictions_DT, y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Random Forests\n",
    "\n",
    "- The RandomForestClassifier is available through the DecisionTree package as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier\n",
       "n_trees:             20\n",
       "n_subfeatures:       -1\n",
       "partial_sampling:    0.7\n",
       "max_depth:           -1\n",
       "min_samples_leaf:    1\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "classes:             nothing\n",
       "ensemble:            nothing"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_trees = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier\n",
       "n_trees:             20\n",
       "n_subfeatures:       -1\n",
       "partial_sampling:    0.7\n",
       "max_depth:           -1\n",
       "min_samples_leaf:    1\n",
       "min_samples_split:   2\n",
       "min_purity_increase: 0.0\n",
       "classes:             [1, 2, 3]\n",
       "ensemble:            Ensemble of Decision Trees\n",
       "Trees:      20\n",
       "Avg Leaves: 5.8\n",
       "Avg Depth:  4.2"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DecisionTree.fit!(model, X[trainids, :], y[trainids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q = X[testids, :];\n",
    "predictions_RF = DecisionTree.predict(model, q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.94"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findaccuracy(predictions_RF, y[testids])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Using a Nearest Neighbor method\n",
    "- We will use the NearestNeighbors package here\n",
    "> * NearestNeighbors.jl is a package written in Julia to perform high performance nearest neighbor searches in arbitrarily high dimensions.\n",
    ">   - https://github.com/KristofferC/NearestNeighbors.jl\n",
    ">   - 줄리아로 모든 함수가 짜여 있음 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KDTree{StaticArrays.SVector{4, Float64}, Euclidean, Float64}\n",
       "  Number of points: 100\n",
       "  Dimensions: 4\n",
       "  Metric: Euclidean(0.0)\n",
       "  Reordered: true"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = X[trainids, :]\n",
    "ytrain = y[trainids]\n",
    "kdtree = KDTree(Xtrain')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- https://blog.naver.com/laonple/221207919855\n",
    "KDTree 설명 참조"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50×4 Matrix{Float64}:\n",
       " 5.1  3.5  1.4  0.2\n",
       " 4.9  3.0  1.4  0.2\n",
       " 4.8  3.0  1.4  0.1\n",
       " 5.4  3.4  1.7  0.2\n",
       " 5.1  3.3  1.7  0.5\n",
       " 5.0  3.0  1.6  0.2\n",
       " 5.2  3.5  1.5  0.2\n",
       " 4.7  3.2  1.6  0.2\n",
       " 5.4  3.4  1.5  0.4\n",
       " 5.5  4.2  1.4  0.2\n",
       " 5.5  3.5  1.3  0.2\n",
       " 4.9  3.6  1.4  0.1\n",
       " 5.0  3.5  1.6  0.6\n",
       " ⋮              \n",
       " 4.9  2.5  4.5  1.7\n",
       " 7.3  2.9  6.3  1.8\n",
       " 6.7  2.5  5.8  1.8\n",
       " 5.8  2.8  5.1  2.4\n",
       " 6.1  3.0  4.9  1.8\n",
       " 6.4  2.8  5.6  2.2\n",
       " 6.3  2.8  5.1  1.5\n",
       " 6.3  3.4  5.6  2.4\n",
       " 6.7  3.1  5.6  2.4\n",
       " 6.8  3.2  5.9  2.3\n",
       " 6.7  3.0  5.2  2.3\n",
       " 6.5  3.0  5.2  2.0"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "queries = X[testids, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[15, 3, 28], [25, 33, 8], [8, 33, 25], [22, 9, 28], [21, 28, 6], [25, 8, 23], [22, 28, 15], [23, 2, 10], [22, 15, 9], [24, 13, 14]  …  [86, 75, 71], [80, 67, 96], [93, 85, 100], [86, 71, 72], [57, 82, 85], [99, 74, 66], [97, 79, 72], [79, 83, 97], [95, 94, 72], [70, 71, 75]], [[0.09999999999999998, 0.1414213562373093, 0.14142135623730964], [0.14142135623730964, 0.14142135623730986, 0.17320508075688784], [0.17320508075688815, 0.19999999999999998, 0.20000000000000037], [0.36055512754639907, 0.3605551275463991, 0.3605551275463995], [0.1999999999999998, 0.3741657386773941, 0.3872983346207416], [0.17320508075688762, 0.19999999999999993, 0.22360679774997916], [0.14142135623730964, 0.14142135623730995, 0.17320508075688806], [0.1414213562373093, 0.17320508075688815, 0.22360679774997858], [0.30000000000000016, 0.3464101615137761, 0.3605551275463992], [0.3464101615137755, 0.3605551275463992, 0.38729833462074176]  …  [0.5567764362830021, 0.6164414002968976, 0.6244997998398398], [0.4898979485566353, 0.5099019513592784, 0.5099019513592784], [0.14142135623730964, 0.24494897427831838, 0.282842712474618], [0.10000000000000009, 0.43588989435406733, 0.46904157598234253], [0.33166247903553975, 0.3741657386773937, 0.4358898943540672], [0.2449489742783171, 0.3872983346207416, 0.42426406871192884], [0.24494897427831785, 0.26457513110645947, 0.34641016151377513], [0.22360679774997935, 0.31622776601683766, 0.31622776601683794], [0.24494897427831822, 0.360555127546399, 0.3741657386773937], [0.22360679774997935, 0.34641016151377513, 0.3605551275463988]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs, dists = knn(kdtree, queries', 3, true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Vector{Vector{Int64}}:\n",
       " [15, 3, 28]\n",
       " [25, 33, 8]\n",
       " [8, 33, 25]\n",
       " [22, 9, 28]\n",
       " [21, 28, 6]\n",
       " [25, 8, 23]\n",
       " [22, 28, 15]\n",
       " [23, 2, 10]\n",
       " [22, 15, 9]\n",
       " [24, 13, 14]\n",
       " [9, 22, 15]\n",
       " [3, 29, 6]\n",
       " [21, 18, 15]\n",
       " ⋮\n",
       " [45, 59, 62]\n",
       " [88, 84, 68]\n",
       " [86, 75, 71]\n",
       " [80, 67, 96]\n",
       " [93, 85, 100]\n",
       " [86, 71, 72]\n",
       " [57, 82, 85]\n",
       " [99, 74, 66]\n",
       " [97, 79, 72]\n",
       " [79, 83, 97]\n",
       " [95, 94, 72]\n",
       " [70, 71, 75]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "digits (generic function with 2 methods)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Vector{Accumulator{Int64, Int64}}:\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " Accumulator(1 => 3)\n",
       " ⋮\n",
       " Accumulator(2 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(2 => 1, 3 => 2)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)\n",
       " Accumulator(3 => 3)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = ytrain[hcat(idxs...)]\n",
    "possible_labels = map(i -> counter(c[:, i]), 1:size(c, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50×1 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m map              \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Dict…            \u001b[0m\n",
      "─────┼──────────────────\n",
      "   1 │ Dict(1=>3)\n",
      "   2 │ Dict(1=>3)\n",
      "   3 │ Dict(1=>3)\n",
      "   4 │ Dict(1=>3)\n",
      "   5 │ Dict(1=>3)\n",
      "   6 │ Dict(1=>3)\n",
      "   7 │ Dict(1=>3)\n",
      "   8 │ Dict(1=>3)\n",
      "   9 │ Dict(1=>3)\n",
      "  10 │ Dict(1=>3)\n",
      "  11 │ Dict(1=>3)\n",
      "  12 │ Dict(1=>3)\n",
      "  13 │ Dict(1=>3)\n",
      "  14 │ Dict(1=>3)\n",
      "  15 │ Dict(2=>3)\n",
      "  16 │ Dict(2=>3)\n",
      "  17 │ Dict(2=>3)\n",
      "  18 │ Dict(2=>3)\n",
      "  19 │ Dict(2=>3)\n",
      "  20 │ Dict(2=>3)\n",
      "  21 │ Dict(2=>1, 3=>2)\n",
      "  22 │ Dict(2=>3)\n",
      "  23 │ Dict(2=>3)\n",
      "  24 │ Dict(2=>2, 3=>1)\n",
      "  25 │ Dict(2=>3)\n",
      "  26 │ Dict(2=>3)\n",
      "  27 │ Dict(2=>3)\n",
      "  28 │ Dict(2=>3)\n",
      "  29 │ Dict(2=>3)\n",
      "  30 │ Dict(2=>3)\n",
      "  31 │ Dict(2=>3)\n",
      "  32 │ Dict(2=>3)\n",
      "  33 │ Dict(2=>3)\n",
      "  34 │ Dict(2=>3)\n",
      "  35 │ Dict(2=>3)\n",
      "  36 │ Dict(3=>3)\n",
      "  37 │ Dict(3=>3)\n",
      "  38 │ Dict(3=>3)\n",
      "  39 │ Dict(2=>3)\n",
      "  40 │ Dict(3=>3)\n",
      "  41 │ Dict(3=>3)\n",
      "  42 │ Dict(3=>3)\n",
      "  43 │ Dict(3=>3)\n",
      "  44 │ Dict(3=>3)\n",
      "  45 │ Dict(2=>1, 3=>2)\n",
      "  46 │ Dict(3=>3)\n",
      "  47 │ Dict(3=>3)\n",
      "  48 │ Dict(3=>3)\n",
      "  49 │ Dict(3=>3)\n",
      "  50 │ Dict(3=>3)"
     ]
    }
   ],
   "source": [
    "print(DataFrame(possible_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accumulator{Int64, Int64} with 2 entries:\n",
       "  2 => 1\n",
       "  3 => 2"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "possible_labels[21]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "argmax(possible_labels[21])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "typeof(argmax(possible_labels[21]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 2\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_NN = map(i -> argmax(possible_labels[i]), 1:size(c,2))\n",
    "# map 함수는 apply 계열 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50×1 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m map              \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Dict…            \u001b[0m\n",
      "─────┼──────────────────\n",
      "   1 │ Dict(1=>3)\n",
      "   2 │ Dict(1=>3)\n",
      "   3 │ Dict(1=>3)\n",
      "   4 │ Dict(1=>3)\n",
      "   5 │ Dict(1=>3)\n",
      "   6 │ Dict(1=>3)\n",
      "   7 │ Dict(1=>3)\n",
      "   8 │ Dict(1=>3)\n",
      "   9 │ Dict(1=>3)\n",
      "  10 │ Dict(1=>3)\n",
      "  11 │ Dict(1=>3)\n",
      "  12 │ Dict(1=>3)\n",
      "  13 │ Dict(1=>3)\n",
      "  14 │ Dict(1=>3)\n",
      "  15 │ Dict(2=>3)\n",
      "  16 │ Dict(2=>3)\n",
      "  17 │ Dict(2=>3)\n",
      "  18 │ Dict(2=>3)\n",
      "  19 │ Dict(2=>3)\n",
      "  20 │ Dict(2=>3)\n",
      "  21 │ Dict(2=>1, 3=>2)\n",
      "  22 │ Dict(2=>3)\n",
      "  23 │ Dict(2=>3)\n",
      "  24 │ Dict(2=>2, 3=>1)\n",
      "  25 │ Dict(2=>3)\n",
      "  26 │ Dict(2=>3)\n",
      "  27 │ Dict(2=>3)\n",
      "  28 │ Dict(2=>3)\n",
      "  29 │ Dict(2=>3)\n",
      "  30 │ Dict(2=>3)\n",
      "  31 │ Dict(2=>3)\n",
      "  32 │ Dict(2=>3)\n",
      "  33 │ Dict(2=>3)\n",
      "  34 │ Dict(2=>3)\n",
      "  35 │ Dict(2=>3)\n",
      "  36 │ Dict(3=>3)\n",
      "  37 │ Dict(3=>3)\n",
      "  38 │ Dict(3=>3)\n",
      "  39 │ Dict(2=>3)\n",
      "  40 │ Dict(3=>3)\n",
      "  41 │ Dict(3=>3)\n",
      "  42 │ Dict(3=>3)\n",
      "  43 │ Dict(3=>3)\n",
      "  44 │ Dict(3=>3)\n",
      "  45 │ Dict(2=>1, 3=>2)\n",
      "  46 │ Dict(3=>3)\n",
      "  47 │ Dict(3=>3)\n",
      "  48 │ Dict(3=>3)\n",
      "  49 │ Dict(3=>3)\n",
      "  50 │ Dict(3=>3)\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 3, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]\n",
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3, 3]"
     ]
    }
   ],
   "source": [
    "print(DataFrame(possible_labels))\n",
    "print(\"\\n\")\n",
    "print(predictions_NN)\n",
    "print(\"\\n\")\n",
    "print(y[testids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "LoadError",
     "evalue": "ArgumentError: All column names must be either Symbols or strings (mixing is not allowed)",
     "output_type": "error",
     "traceback": [
      "ArgumentError: All column names must be either Symbols or strings (mixing is not allowed)",
      "",
      "Stacktrace:",
      "  [1] DataFrame(d::Accumulator{Int64, Int64}; copycols::Bool)",
      "    @ DataFrames ~\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:252",
      "  [2] DataFrame(d::Accumulator{Int64, Int64})",
      "    @ DataFrames ~\\.julia\\packages\\DataFrames\\3mEXm\\src\\dataframe\\dataframe.jl:247",
      "  [3] (::var\"#17#18\")(i::Int64)",
      "    @ Main .\\In[66]:1",
      "  [4] iterate",
      "    @ .\\generator.jl:47 [inlined]",
      "  [5] _collect(c::UnitRange{Int64}, itr::Base.Generator{UnitRange{Int64}, var\"#17#18\"}, #unused#::Base.EltypeUnknown, isz::Base.HasShape{1})",
      "    @ Base .\\array.jl:691",
      "  [6] collect_similar(cont::UnitRange{Int64}, itr::Base.Generator{UnitRange{Int64}, var\"#17#18\"})",
      "    @ Base .\\array.jl:606",
      "  [7] map(f::Function, A::UnitRange{Int64})",
      "    @ Base .\\abstractarray.jl:2294",
      "  [8] top-level scope",
      "    @ In[66]:1",
      "  [9] eval",
      "    @ .\\boot.jl:360 [inlined]",
      " [10] include_string(mapexpr::typeof(REPL.softscope), mod::Module, code::String, filename::String)",
      "    @ Base .\\loading.jl:1094"
     ]
    }
   ],
   "source": [
    "# 원코드의 함수  -> 에러 나옴\n",
    "predictions_NN = map(i->parse(Int,string(argmax(DataFrame(possible_labels[i])[1,:]))),1:size(c,2))\n",
    "findaccuracy(predictions_NN,y[testids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.96"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findaccuracy(predictions_NN,y[testids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"data-frame\"><thead><tr><th></th><th>pred</th><th>real</th><th>diff</th></tr><tr><th></th><th>Int64</th><th>Int64</th><th>Int64</th></tr></thead><tbody><p>50 rows × 3 columns</p><tr><th>1</th><td>1</td><td>1</td><td>0</td></tr><tr><th>2</th><td>1</td><td>1</td><td>0</td></tr><tr><th>3</th><td>1</td><td>1</td><td>0</td></tr><tr><th>4</th><td>1</td><td>1</td><td>0</td></tr><tr><th>5</th><td>1</td><td>1</td><td>0</td></tr><tr><th>6</th><td>1</td><td>1</td><td>0</td></tr><tr><th>7</th><td>1</td><td>1</td><td>0</td></tr><tr><th>8</th><td>1</td><td>1</td><td>0</td></tr><tr><th>9</th><td>1</td><td>1</td><td>0</td></tr><tr><th>10</th><td>1</td><td>1</td><td>0</td></tr><tr><th>11</th><td>1</td><td>1</td><td>0</td></tr><tr><th>12</th><td>1</td><td>1</td><td>0</td></tr><tr><th>13</th><td>1</td><td>1</td><td>0</td></tr><tr><th>14</th><td>1</td><td>1</td><td>0</td></tr><tr><th>15</th><td>2</td><td>2</td><td>0</td></tr><tr><th>16</th><td>2</td><td>2</td><td>0</td></tr><tr><th>17</th><td>2</td><td>2</td><td>0</td></tr><tr><th>18</th><td>2</td><td>2</td><td>0</td></tr><tr><th>19</th><td>2</td><td>2</td><td>0</td></tr><tr><th>20</th><td>2</td><td>2</td><td>0</td></tr><tr><th>21</th><td>3</td><td>2</td><td>1</td></tr><tr><th>22</th><td>2</td><td>2</td><td>0</td></tr><tr><th>23</th><td>2</td><td>2</td><td>0</td></tr><tr><th>24</th><td>2</td><td>2</td><td>0</td></tr><tr><th>25</th><td>2</td><td>2</td><td>0</td></tr><tr><th>26</th><td>2</td><td>2</td><td>0</td></tr><tr><th>27</th><td>2</td><td>2</td><td>0</td></tr><tr><th>28</th><td>2</td><td>2</td><td>0</td></tr><tr><th>29</th><td>2</td><td>2</td><td>0</td></tr><tr><th>30</th><td>2</td><td>2</td><td>0</td></tr><tr><th>&vellip;</th><td>&vellip;</td><td>&vellip;</td><td>&vellip;</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccc}\n",
       "\t& pred & real & diff\\\\\n",
       "\t\\hline\n",
       "\t& Int64 & Int64 & Int64\\\\\n",
       "\t\\hline\n",
       "\t1 & 1 & 1 & 0 \\\\\n",
       "\t2 & 1 & 1 & 0 \\\\\n",
       "\t3 & 1 & 1 & 0 \\\\\n",
       "\t4 & 1 & 1 & 0 \\\\\n",
       "\t5 & 1 & 1 & 0 \\\\\n",
       "\t6 & 1 & 1 & 0 \\\\\n",
       "\t7 & 1 & 1 & 0 \\\\\n",
       "\t8 & 1 & 1 & 0 \\\\\n",
       "\t9 & 1 & 1 & 0 \\\\\n",
       "\t10 & 1 & 1 & 0 \\\\\n",
       "\t11 & 1 & 1 & 0 \\\\\n",
       "\t12 & 1 & 1 & 0 \\\\\n",
       "\t13 & 1 & 1 & 0 \\\\\n",
       "\t14 & 1 & 1 & 0 \\\\\n",
       "\t15 & 2 & 2 & 0 \\\\\n",
       "\t16 & 2 & 2 & 0 \\\\\n",
       "\t17 & 2 & 2 & 0 \\\\\n",
       "\t18 & 2 & 2 & 0 \\\\\n",
       "\t19 & 2 & 2 & 0 \\\\\n",
       "\t20 & 2 & 2 & 0 \\\\\n",
       "\t21 & 3 & 2 & 1 \\\\\n",
       "\t22 & 2 & 2 & 0 \\\\\n",
       "\t23 & 2 & 2 & 0 \\\\\n",
       "\t24 & 2 & 2 & 0 \\\\\n",
       "\t25 & 2 & 2 & 0 \\\\\n",
       "\t26 & 2 & 2 & 0 \\\\\n",
       "\t27 & 2 & 2 & 0 \\\\\n",
       "\t28 & 2 & 2 & 0 \\\\\n",
       "\t29 & 2 & 2 & 0 \\\\\n",
       "\t30 & 2 & 2 & 0 \\\\\n",
       "\t$\\dots$ & $\\dots$ & $\\dots$ & $\\dots$ \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "\u001b[1m50×3 DataFrame\u001b[0m\n",
       "\u001b[1m Row \u001b[0m│\u001b[1m pred  \u001b[0m\u001b[1m real  \u001b[0m\u001b[1m diff  \u001b[0m\n",
       "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
       "─────┼─────────────────────\n",
       "   1 │     1      1      0\n",
       "   2 │     1      1      0\n",
       "   3 │     1      1      0\n",
       "   4 │     1      1      0\n",
       "   5 │     1      1      0\n",
       "   6 │     1      1      0\n",
       "   7 │     1      1      0\n",
       "   8 │     1      1      0\n",
       "   9 │     1      1      0\n",
       "  10 │     1      1      0\n",
       "  11 │     1      1      0\n",
       "  ⋮  │   ⋮      ⋮      ⋮\n",
       "  41 │     3      3      0\n",
       "  42 │     3      3      0\n",
       "  43 │     3      3      0\n",
       "  44 │     3      3      0\n",
       "  45 │     3      3      0\n",
       "  46 │     3      3      0\n",
       "  47 │     3      3      0\n",
       "  48 │     3      3      0\n",
       "  49 │     3      3      0\n",
       "  50 │     3      3      0\n",
       "\u001b[36m            29 rows omitted\u001b[0m"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_df = DataFrame(\"pred\" => predictions_NN, \"real\" => y[testids], \"diff\" =>  predictions_NN-y[testids] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m50×3 DataFrame\u001b[0m\n",
      "\u001b[1m Row \u001b[0m│\u001b[1m pred  \u001b[0m\u001b[1m real  \u001b[0m\u001b[1m diff  \u001b[0m\n",
      "\u001b[1m     \u001b[0m│\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\u001b[90m Int64 \u001b[0m\n",
      "─────┼─────────────────────\n",
      "   1 │     1      1      0\n",
      "   2 │     1      1      0\n",
      "   3 │     1      1      0\n",
      "   4 │     1      1      0\n",
      "   5 │     1      1      0\n",
      "   6 │     1      1      0\n",
      "   7 │     1      1      0\n",
      "   8 │     1      1      0\n",
      "   9 │     1      1      0\n",
      "  10 │     1      1      0\n",
      "  11 │     1      1      0\n",
      "  12 │     1      1      0\n",
      "  13 │     1      1      0\n",
      "  14 │     1      1      0\n",
      "  15 │     2      2      0\n",
      "  16 │     2      2      0\n",
      "  17 │     2      2      0\n",
      "  18 │     2      2      0\n",
      "  19 │     2      2      0\n",
      "  20 │     2      2      0\n",
      "  21 │     3      2      1\n",
      "  22 │     2      2      0\n",
      "  23 │     2      2      0\n",
      "  24 │     2      2      0\n",
      "  25 │     2      2      0\n",
      "  26 │     2      2      0\n",
      "  27 │     2      2      0\n",
      "  28 │     2      2      0\n",
      "  29 │     2      2      0\n",
      "  30 │     2      2      0\n",
      "  31 │     2      2      0\n",
      "  32 │     2      2      0\n",
      "  33 │     2      2      0\n",
      "  34 │     2      2      0\n",
      "  35 │     2      2      0\n",
      "  36 │     3      3      0\n",
      "  37 │     3      3      0\n",
      "  38 │     3      3      0\n",
      "  39 │     2      3     -1\n",
      "  40 │     3      3      0\n",
      "  41 │     3      3      0\n",
      "  42 │     3      3      0\n",
      "  43 │     3      3      0\n",
      "  44 │     3      3      0\n",
      "  45 │     3      3      0\n",
      "  46 │     3      3      0\n",
      "  47 │     3      3      0\n",
      "  48 │     3      3      0\n",
      "  49 │     3      3      0\n",
      "  50 │     3      3      0"
     ]
    }
   ],
   "source": [
    "print(temp_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 검증 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SVM(Support Vector Machines)\n",
    "- We will use the `LIBSVM` package here\n",
    "\n",
    "> https://github.com/JuliaML/LIBSVM.jl\n",
    "\n",
    "\n",
    "> https://www.csie.ntu.edu.tw/~cjlin/libsvm/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100-element Vector{Int64}:\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " 1\n",
       " ⋮\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3\n",
       " 3"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain = X[trainids, :]\n",
    "ytrain = y[trainids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LIBSVM.SVM{Int64}(SVC, LIBSVM.Kernel.RadialBasis, nothing, 4, 3, [1, 2, 3], Int32[1, 2, 3], Float64[], Int32[], LIBSVM.SupportVectors{Int64, Float64}(36, Int32[6, 14, 16], [1, 1, 1, 1, 1, 1, 2, 2, 2, 2  …  3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [4.3 5.7 … 6.3 5.9; 3.0 4.4 … 2.5 3.0; 1.1 1.5 … 5.0 5.1; 0.1 0.4 … 1.9 1.8], Int32[11, 13, 16, 20, 30, 32, 37, 39, 41, 42  …  82, 85, 87, 89, 90, 93, 95, 96, 98, 100], LIBSVM.SVMNode[LIBSVM.SVMNode(1, 4.3), LIBSVM.SVMNode(1, 5.7), LIBSVM.SVMNode(1, 5.7), LIBSVM.SVMNode(1, 4.8), LIBSVM.SVMNode(1, 4.5), LIBSVM.SVMNode(1, 5.1), LIBSVM.SVMNode(1, 7.0), LIBSVM.SVMNode(1, 6.9), LIBSVM.SVMNode(1, 6.5), LIBSVM.SVMNode(1, 6.3)  …  LIBSVM.SVMNode(1, 6.3), LIBSVM.SVMNode(1, 6.2), LIBSVM.SVMNode(1, 7.2), LIBSVM.SVMNode(1, 7.9), LIBSVM.SVMNode(1, 6.1), LIBSVM.SVMNode(1, 6.0), LIBSVM.SVMNode(1, 6.9), LIBSVM.SVMNode(1, 5.8), LIBSVM.SVMNode(1, 6.3), LIBSVM.SVMNode(1, 5.9)]), 0.0, [0.0 0.04328020851343606; 0.43954679567868465 0.9047809464113701; … ; -0.0 -1.0; -0.0 -1.0], Float64[], Float64[], [0.040108492051354375, 0.10874503622972502, 0.14453271415780214], 3, 0.25, 200.0, 0.001, 1.0, 0.5, 0.1, true, false)"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = svmtrain(Xtrain', ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([1, 1, 1, 1, 1, 1, 1, 1, 1, 1  …  3, 3, 3, 3, 3, 3, 3, 3, 3, 3], [1.238486216673677 1.1816741085391615 … -0.7851730822247001 -0.8892808489546852; 1.133911522560622 1.121930201818705 … -1.062793861648126 -1.1017855054534904; 0.09504587304145165 0.11448678438948887 … -1.2626302256411652 -0.9533465403643183])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_SVM, dicistion_values = svmpredict(model, X[testids, :]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.98"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "findaccuracy(predictions_SVM, y[testids])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7×2 Matrix{Any}:\n",
       " \"lasso\"  0.96\n",
       " \"ridge\"  0.94\n",
       " \"EN\"     0.94\n",
       " \"DT\"     0.92\n",
       " \"RF\"     0.94\n",
       " \"kNN\"    0.96\n",
       " \"SVM\"    0.98"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overall_accuracies = zeros(7)\n",
    "methods = [\"lasso\",\"ridge\",\"EN\", \"DT\", \"RF\",\"kNN\", \"SVM\"]\n",
    "ytest = y[testids]\n",
    "overall_accuracies[1] = findaccuracy(pred_class_lasso,ytest)\n",
    "overall_accuracies[2] = findaccuracy(pred_class_ridge,ytest)\n",
    "overall_accuracies[3] = findaccuracy(pred_class_EN,ytest)\n",
    "overall_accuracies[4] = findaccuracy(predictions_DT,ytest)\n",
    "overall_accuracies[5] = findaccuracy(predictions_RF,ytest)\n",
    "overall_accuracies[6] = findaccuracy(predictions_NN,ytest)\n",
    "overall_accuracies[7] = findaccuracy(predictions_SVM,ytest)\n",
    "hcat(methods, overall_accuracies)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finally...\n",
    "After finishing this notebook, you should be able to:\n",
    "- [ ] split your data into training and testing data to test the effectiveness of a certain method\n",
    "- [ ] apply a simple accuracy function to test the effectiveness of a certain method\n",
    "- [ ] run multiple classification algorithms:\n",
    "    - [ ] LASSO\n",
    "    - [ ] Ridge\n",
    "    - [ ] ElasticNet\n",
    "    - [ ] Decision Tree\n",
    "    - [ ] Random Forest\n",
    "    - [ ] Nearest Neighbors\n",
    "    - [ ] Support Vector Machines"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.0",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
